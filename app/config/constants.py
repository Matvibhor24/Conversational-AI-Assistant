GEMINI_MODEL = "gemini-2.5-flash"
OPENAI_MODEL = "gemini-2.5-flash"
# OPENAI_MODEL = "gpt-4o-mini"

# Token limits for conversation context management
MAX_CONTEXT_TOKENS = 2000  # Maximum tokens for conversation context in prompts
MAX_TURNS_BEFORE_SUMMARY = 6  # Number of turns before triggering summarization
MIN_TURNS_TO_KEEP = 2  # Minimum recent turns to keep after summarization
